const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const axios = require('axios');
const { getValidAccessTokenWithRefresh, loadTokens } = require('../services/tokenStorage');

// Jobs storage
const jobs = new Map(); // manifestId -> { status, startedAt, logFile, process }

// Check if user has admin approval for OneDrive access
async function checkOneDriveApproval(userId) {
  console.log(`üîç Checking OneDrive approval for user: ${userId}`);
  
  try {
    const accessToken = await getValidAccessTokenWithRefresh(userId);
    
    // Test OneDrive access via Microsoft Graph API
    const response = await axios.get('https://graph.microsoft.com/v1.0/me/drive', {
      headers: {
        'Authorization': `Bearer ${accessToken}`,
        'Content-Type': 'application/json'
      }
    });
    
    console.log(`‚úÖ OneDrive access approved for user: ${userId}`);
    return { approved: true, driveId: response.data.id };
    
  } catch (error) {
    if (error.response?.status === 403) {
      console.log(`‚ùå OneDrive access denied for user: ${userId} - Admin approval required`);
      return { approved: false, error: 'Admin approval required for OneDrive access' };
    }
    
    console.error(`‚ùå Error checking OneDrive approval:`, error.message);
    throw new Error(`Failed to check OneDrive approval: ${error.message}`);
  }
}

// Validate and refresh token before migration
async function validateTokenForMigration(userId) {
  console.log(`üîê Validating token for migration - user: ${userId}`);
  
  try {
    const tokens = loadTokens();
    const tokenData = tokens[userId];
    
    if (!tokenData) {
      throw new Error(`No token data found for user ${userId}`);
    }
    
    // Check if token is expired or will expire soon (within 5 minutes)
    const expiresAt = new Date(tokenData.expiresAt);
    const fiveMinutesFromNow = new Date(Date.now() + 5 * 60 * 1000);
    
    if (expiresAt <= fiveMinutesFromNow) {
      console.log(`üîÑ Token expires soon, refreshing...`);
      await getValidAccessTokenWithRefresh(userId);
    }
    
    console.log(`‚úÖ Token validated for migration`);
    return true;
    
  } catch (error) {
    console.error(`‚ùå Token validation failed:`, error.message);
    throw error;
  }
}

// Ensure rclone remotes are properly configured
async function ensureRcloneRemotes(userId) {
  console.log(`üîß Ensuring rclone remotes for user: ${userId}`);
  
  try {
    const configPath = process.env.RCLONE_CONFIG_PATH || path.join(__dirname, '../../config/rclone.conf');
    
    // Create config directory if it doesn't exist
    const configDir = path.dirname(configPath);
    if (!fs.existsSync(configDir)) {
      fs.mkdirSync(configDir, { recursive: true });
    }
    
    // Initialize config file if it doesn't exist
    if (!fs.existsSync(configPath)) {
      const defaultConfig = `# Rclone configuration for OneDrive to Backblaze B2 Migration

[onedrive]
type = onedrive
token = {"access_token":"","token_type":"Bearer","refresh_token":"","expiry":"2006-01-02T15:04:05Z"}
drive_id = 
drive_type = personal

[b2]
type = b2
account = ${process.env.B2_APPLICATION_KEY_ID || 'your_b2_account_id_here'}
key = ${process.env.B2_APPLICATION_KEY || 'your_b2_application_key_here'}
endpoint = 
`;
      fs.writeFileSync(configPath, defaultConfig);
      console.log(`‚úÖ Created rclone config file at: ${configPath}`);
    }
    
    // Always update B2 credentials from environment variables
    let b2ConfigContent = fs.readFileSync(configPath, 'utf8');
    
    // Update B2 credentials if environment variables are available
    if (process.env.B2_APPLICATION_KEY_ID && process.env.B2_APPLICATION_KEY) {
      // Update account line
      b2ConfigContent = b2ConfigContent.replace(
        /account = .*/,
        `account = ${process.env.B2_APPLICATION_KEY_ID}`
      );
      
      // Update key line
      b2ConfigContent = b2ConfigContent.replace(
        /key = .*/,
        `key = ${process.env.B2_APPLICATION_KEY}`
      );
      
      fs.writeFileSync(configPath, b2ConfigContent);
      console.log(`‚úÖ Updated rclone config with B2 credentials`);
    }
    
    // Get current valid access token
    const accessToken = await getValidAccessTokenWithRefresh(userId);
    
    // Get drive information from Microsoft Graph API
    let driveId = 'me';
    let driveType = 'personal';
    
    try {
      const driveResponse = await axios.get('https://graph.microsoft.com/v1.0/me/drive', {
        headers: {
          'Authorization': `Bearer ${accessToken}`,
          'Content-Type': 'application/json'
        }
      });
      
      if (driveResponse.data && driveResponse.data.id) {
        driveId = driveResponse.data.id;
        driveType = driveResponse.data.driveType || 'personal';
        console.log(`‚úÖ Retrieved drive info: ID=${driveId}, Type=${driveType}`);
      }
    } catch (error) {
      console.log(`‚ö†Ô∏è Could not fetch drive info, using defaults: ${error.message}`);
    }
    
    // Read existing config
    let configContent = fs.readFileSync(configPath, 'utf8');
    
    // Update the OneDrive token with the current valid token
    // We need to construct the full token object that rclone expects
    const tokens = loadTokens();
    const tokenData = tokens[userId];
    
    if (tokenData) {
      const tokenObject = {
        access_token: accessToken,
        token_type: "Bearer",
        refresh_token: tokenData.refreshToken,
        expiry: tokenData.expiresAt
      };
      
      const tokenRegex = /token = \{.*?\}/s;
      const newToken = `token = ${JSON.stringify(tokenObject)}`;
      
      if (tokenRegex.test(configContent)) {
        configContent = configContent.replace(tokenRegex, newToken);
        
        // Also update drive_id and drive_type
        configContent = configContent.replace(/drive_id = .*/, `drive_id = ${driveId}`);
        configContent = configContent.replace(/drive_type = .*/, `drive_type = ${driveType}`);
        
        fs.writeFileSync(configPath, configContent);
        console.log(`‚úÖ Updated rclone config with fresh token and drive info`);
      } else {
        console.log(`‚ö†Ô∏è Could not find token in rclone config to update`);
      }
    } else {
      console.log(`‚ö†Ô∏è No token data found for user ${userId}`);
    }
    
    // Check if OneDrive remote exists
    if (!configContent.includes('[onedrive]')) {
      throw new Error('OneDrive remote not found in rclone config');
    }
    
    // Check if B2 remote exists
    if (!configContent.includes('[b2]')) {
      throw new Error('B2 remote not found in rclone config');
    }
    
    console.log(`‚úÖ Rclone remotes configured`);
    return {
      onedriveRemote: 'onedrive',
      b2Remote: 'b2',
      configPath: configPath
    };
    
  } catch (error) {
    console.error(`‚ùå Rclone remote configuration failed:`, error.message);
    throw error;
  }
}

// Start migration job with comprehensive error handling
async function startMigration(userId, items, dstPrefix = '') {
  console.log(`üöÄ Starting migration for user: ${userId}`);
  console.log(`   Items: ${items.length}`);
  console.log(`   Destination prefix: ${dstPrefix || userId}`);
  
  if (!items || items.length === 0) {
    throw new Error('No items to migrate');
  }
  
  // Create manifest ID (idempotent)
  const manifestId = crypto.createHash('sha1')
    .update(userId + JSON.stringify(items) + (dstPrefix || ''))
    .digest('hex');
  
  console.log(`   Manifest ID: ${manifestId}`);
  
  // Check if job is already running
  const existingJob = jobs.get(manifestId);
  if (existingJob && existingJob.status === 'running') {
    console.log(`‚ö†Ô∏è Job already running for manifest: ${manifestId}`);
    return { manifestId, status: 'already_running' };
  }
  
  try {
    // Step 1: Validate token
    await validateTokenForMigration(userId);
    
    // Step 2: Check OneDrive approval
    const approvalCheck = await checkOneDriveApproval(userId);
    if (!approvalCheck.approved) {
      throw new Error(approvalCheck.error);
    }
    
    // Step 3: Ensure rclone remotes
    const remotes = await ensureRcloneRemotes(userId);
    
    // Step 4: Create manifest file
    const manifestFile = path.join(__dirname, `${manifestId}.txt`);
    fs.writeFileSync(manifestFile, items.join('\n'));
    console.log(`   Manifest file: ${manifestFile}`);
    
    // Step 5: Create log file
    const logsDir = path.join(__dirname, '../logs');
    if (!fs.existsSync(logsDir)) {
      fs.mkdirSync(logsDir, { recursive: true });
    }
    const logFile = path.join(logsDir, `${manifestId}.log`);
    const logStream = fs.createWriteStream(logFile, { flags: 'a' });
    
    // Step 6: Build destination
    const bucketName = process.env.B2_BUCKET_NAME || 'onedrive-migrations';
    const dst = `${remotes.b2Remote}:${bucketName}/${dstPrefix || userId}`;
    
    // Step 7: Rclone arguments
    const args = [
      'copy',
      `${remotes.onedriveRemote}:`,
      dst,
      '--files-from', manifestFile,
      '--progress',
      '--transfers', '8',
      '--checkers', '8',
      '--retries', '3',
      '--low-level-retries', '5',
      '--stats', '1s',
      '--buffer-size', '16M',
      '--config', remotes.configPath
    ];
    
    console.log(`   Rclone command: rclone ${args.join(' ')}`);
    
    // Step 8: Start rclone process
    const rclonePath = process.env.RCLONE_PATH || 'rclone';
    const child = spawn(rclonePath, args, { 
      env: { ...process.env, RCLONE_CONFIG: remotes.configPath },
      stdio: ['pipe', 'pipe', 'pipe']
    });
    
    // Step 9: Store job info
    jobs.set(manifestId, { 
      status: 'running', 
      startedAt: new Date(), 
      logFile,
      process: child,
      manifestFile,
      userId,
      items: items.length,
      destination: dst
    });
    
    // Step 10: Handle stdout
    child.stdout.on('data', (data) => {
      const output = data.toString();
      try {
        logStream.write(output);
      } catch (streamError) {
        console.error(`[${manifestId}] Stream write error:`, streamError.message);
      }
      console.log(`[${manifestId}] ${output.trim()}`);
    });
    
    // Step 11: Handle stderr
    child.stderr.on('data', (data) => {
      const output = data.toString();
      try {
        logStream.write(output);
      } catch (streamError) {
        console.error(`[${manifestId}] Stream write error:`, streamError.message);
      }
      console.log(`[${manifestId}] ERROR: ${output.trim()}`);
    });
    
    // Step 12: Handle process close
    child.on('close', (code) => {
      try {
        logStream.write(`\nEXIT ${code}\n`);
        logStream.end();
      } catch (streamError) {
        console.error(`[${manifestId}] Stream write error:`, streamError.message);
      }
      
      const job = jobs.get(manifestId);
      if (job) {
        job.status = code === 0 ? 'completed' : 'failed';
        job.finishedAt = new Date();
        job.exitCode = code;
        delete job.process; // Remove process reference
        
        // Clean up manifest file
        try {
          fs.unlinkSync(job.manifestFile);
        } catch (e) {
          console.error(`Failed to delete manifest file: ${e.message}`);
        }
      }
      
      console.log(`[${manifestId}] Process finished with code: ${code}`);
    });
    
    // Step 13: Handle process error
    child.on('error', (error) => {
      try {
        logStream.write(`\nPROCESS ERROR: ${error.message}\n`);
        logStream.end();
      } catch (streamError) {
        console.error(`[${manifestId}] Stream write error:`, streamError.message);
      }
      
      const job = jobs.get(manifestId);
      if (job) {
        job.status = 'failed';
        job.finishedAt = new Date();
        job.error = error.message;
        delete job.process;
      }
      
      console.error(`[${manifestId}] Process error:`, error.message);
    });
    
    console.log(`‚úÖ Migration started successfully for manifest: ${manifestId}`);
    return { manifestId, status: 'started' };
    
  } catch (error) {
    console.error(`‚ùå Failed to start migration:`, error.message);
    throw error;
  }
}

// Get job status
function getJobStatus(manifestId) {
  return jobs.get(manifestId) || null;
}

// Get all jobs
function getAllJobs() {
  return Array.from(jobs.entries()).map(([id, job]) => ({
    manifestId: id,
    ...job
  }));
}

// Stop job
function stopJob(manifestId) {
  const job = jobs.get(manifestId);
  if (job && job.process) {
    job.process.kill('SIGTERM');
    job.status = 'stopped';
    job.finishedAt = new Date();
    console.log(`[${manifestId}] Job stopped`);
    return true;
  }
  return false;
}

// Get job logs
function getJobLogs(manifestId) {
  const job = jobs.get(manifestId);
  if (!job || !job.logFile) {
    return null;
  }
  
  try {
    return fs.readFileSync(job.logFile, 'utf8');
  } catch (error) {
    console.error(`Failed to read log file: ${error.message}`);
    return null;
  }
}

// Test OneDrive connection
async function testOneDriveConnection(userId) {
  console.log(`üß™ Testing OneDrive connection for user: ${userId}`);
  
  try {
    // Validate token
    await validateTokenForMigration(userId);
    
    // Check approval
    const approvalCheck = await checkOneDriveApproval(userId);
    if (!approvalCheck.approved) {
      return { success: false, error: approvalCheck.error };
    }
    
    // Test rclone access
    const remotes = await ensureRcloneRemotes(userId);
    const rclonePath = process.env.RCLONE_PATH || 'rclone';
    
    const testOutput = require('child_process').execSync(
      `"${rclonePath}" lsd "${remotes.onedriveRemote}:" --config "${remotes.configPath}"`,
      { stdio: 'pipe' }
    );
    
    console.log(`‚úÖ OneDrive connection test passed`);
    return { success: true, output: testOutput.toString() };
    
  } catch (error) {
    console.error(`‚ùå OneDrive connection test failed:`, error.message);
    return { success: false, error: error.message };
  }
}

// Test B2 connection
async function testB2Connection() {
  console.log(`üß™ Testing B2 connection`);
  
  try {
    const configPath = process.env.RCLONE_CONFIG_PATH || path.join(__dirname, '../../config/rclone.conf');
    const rclonePath = process.env.RCLONE_PATH || 'rclone';
    
    const testOutput = require('child_process').execSync(
      `"${rclonePath}" lsd "b2:" --config "${configPath}"`,
      { stdio: 'pipe' }
    );
    
    console.log(`‚úÖ B2 connection test passed`);
    return { success: true, output: testOutput.toString() };
    
  } catch (error) {
    console.error(`‚ùå B2 connection test failed:`, error.message);
    return { success: false, error: error.message };
  }
}

module.exports = {
  startMigration,
  getJobStatus,
  getAllJobs,
  stopJob,
  getJobLogs,
  testOneDriveConnection,
  testB2Connection,
  checkOneDriveApproval,
  validateTokenForMigration,
  ensureRcloneRemotes
};


